{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0349b0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328a807e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ======== 1. Load IndoBERT dan model hasil training kamu ========\n",
    "MODEL_NAME = \"indobenchmark/indobert-base-p1\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = TFBertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "model.load_weights(\"result/tf_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2c35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 2. Fungsi prediksi sentimen ========\n",
    "label_map = {0: \"Negatif\", 1: \"Netral\", 2: \"Positif\"}\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"tf\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    outputs = model(inputs)\n",
    "    probs = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "    label_id = tf.argmax(probs, axis=1).numpy()[0]\n",
    "    confidence = float(tf.reduce_max(probs).numpy())\n",
    "    return label_map[label_id], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06bdb581",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASPECT_KEYWORDS = {\n",
    "    \"aroma\": [\"aroma\", \"wangi\", \"bau\", \"harum\", \"semerbak\", \"wanginya\"],\n",
    "    \"harga\": [\"harga\", \"mahal\", \"murah\", \"diskon\", \"promo\"],\n",
    "    \"kemasan\": [\"kemasan\", \"botol\", \"desain\", \"tutup\", \"packaging\", \"kotak\"],\n",
    "    \"ketahanan\": [\"tahan\", \"daya tahan\", \"lama\", \"cepat hilang\", \"awet\"],\n",
    "    \"kualitas\": [\"kualitas\", \"bagus\", \"jelek\", \"baik\", \"buruk\", \"premium\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850b0655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 4. Fungsi deteksi aspek dari teks ========\n",
    "def detect_aspect(text):\n",
    "    found_aspects = []\n",
    "    lower_text = text.lower()\n",
    "    for aspect, keywords in ASPECT_KEYWORDS.items():\n",
    "        if any(word in lower_text for word in keywords):\n",
    "            found_aspects.append(aspect)\n",
    "    return found_aspects if found_aspects else [\"umum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469a356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 5. Fungsi ABSA utama ========\n",
    "def absa_predict(text):\n",
    "    aspects = detect_aspect(text)\n",
    "    results = {}\n",
    "\n",
    "    for aspect in aspects:\n",
    "        # Ambil subteks terkait aspek\n",
    "        sentences = [s for s in text.split('.') if aspect in s.lower()]\n",
    "        sub_text = \" \".join(sentences) if sentences else text\n",
    "\n",
    "        sentiment, conf = predict_sentiment(sub_text)\n",
    "        results[aspect] = {\"sentiment\": sentiment, \"confidence\": round(conf, 3)}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99661503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Aspect-Based Sentiment Analysis (ABSA) ===\n",
      "\n",
      "Hasil Analisis:\n",
      "- Aroma → Positif (confidence: 0.951)\n",
      "- Kualitas → Positif (confidence: 0.951)\n"
     ]
    }
   ],
   "source": [
    "# ======== 6. Testing dengan input user ========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Aspect-Based Sentiment Analysis (ABSA) ===\")\n",
    "    user_text = input(\"Masukkan review parfum: \")\n",
    "\n",
    "    results = absa_predict(user_text)\n",
    "    print(\"\\nHasil Analisis:\")\n",
    "    for aspect, info in results.items():\n",
    "        print(f\"- {aspect.capitalize()} → {info['sentiment']} (confidence: {info['confidence']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
