{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "844ed8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers tensorflow pandas scikit-learn openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74aa2226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  label\n",
      "0  Q kira besar ,ternyata miniü§≠ü§≠ tapi cocok sic d...      1\n",
      "1  Koyok ngengek, yg dikirim minyak 1 mili iklan ...      0\n",
      "2  Saya kira awalnya minyak wangi Fress beneran, ...      1\n",
      "3  Baik, harum sekali, testyr kurang besar, murah...      2\n",
      "4  Produk sesuai dengan pesanan pengiriman tepat ...      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ganti path ke file kamu\n",
    "DATA_PATH = r\"Dataset Text Web.xlsx\"\n",
    "\n",
    "# Misalnya sheet berisi kolom: \"text\" dan \"label\"\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "\n",
    "# Cek dulu struktur datanya\n",
    "print(df.head())\n",
    "\n",
    "# Split data menjadi train & test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"review\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c0f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at indobert-base-p1 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "MODEL_PATH = r\"indobert-base-p1\"\n",
    "SAVED_PATH = r\"result\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=len(df[\"label\"].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "526cddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    list(train_texts),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"tf\"\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    list(test_texts),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"tf\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "708c202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.convert_to_tensor(list(train_labels))\n",
    "test_labels = tf.convert_to_tensor(list(test_labels))\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(100).batch(16)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    ")).batch(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "726bb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\javier\\anaconda3\\envs\\tf\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "108/108 [==============================] - 527s 5s/step - loss: 0.4830 - accuracy: 0.7952 - val_loss: 0.2654 - val_accuracy: 0.9044\n",
      "Epoch 2/3\n",
      "108/108 [==============================] - 516s 5s/step - loss: 0.2234 - accuracy: 0.9224 - val_loss: 0.2219 - val_accuracy: 0.9301\n",
      "Epoch 3/3\n",
      "108/108 [==============================] - 525s 5s/step - loss: 0.1136 - accuracy: 0.9685 - val_loss: 0.3632 - val_accuracy: 0.9021\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,\n",
    "    validation_data=test_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc2e99d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 35s 1s/step\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9704    0.9213    0.9452       178\n",
      "           1     0.8069    0.9070    0.8540       129\n",
      "           2     0.9217    0.8689    0.8945       122\n",
      "\n",
      "    accuracy                         0.9021       429\n",
      "   macro avg     0.8997    0.8991    0.8979       429\n",
      "weighted avg     0.9074    0.9021    0.9034       429\n",
      "\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[164  13   1]\n",
      " [  4 117   8]\n",
      " [  1  15 106]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ==============================\n",
    "# üîç Evaluasi Model\n",
    "# ==============================\n",
    "\n",
    "# 1Ô∏è‚É£ Ambil prediksi model pada test set\n",
    "y_pred_logits = model.predict(test_dataset).logits  # ambil logits\n",
    "y_pred = np.argmax(y_pred_logits, axis=1)           # ambil kelas prediksi\n",
    "\n",
    "# 2Ô∏è‚É£ Ambil label asli (ground truth)\n",
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "\n",
    "# 3Ô∏è‚É£ Print classification report\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# 4Ô∏è‚É£ (Opsional) Print confusion matrix\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e15217b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 151s 3s/step\n",
      "14/14 [==============================] - 38s 3s/step\n",
      "Training Accuracy: 0.9609\n",
      "Test Accuracy: 0.9021\n",
      "Gap: 0.0588\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prediksi probabilitas (logits)\n",
    "y_train_pred_logits = model.predict(train_encodings).logits\n",
    "y_test_pred_logits = model.predict(test_encodings).logits\n",
    "\n",
    "# Ambil kelas dengan probabilitas tertinggi\n",
    "y_train_pred = np.argmax(y_train_pred_logits, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred_logits, axis=1)\n",
    "\n",
    "# Hitung akurasi\n",
    "train_acc = accuracy_score(train_labels, y_train_pred)\n",
    "test_acc = accuracy_score(test_labels, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Gap: {train_acc - test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f98cfaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model berhasil disimpan di result\n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = r\"result\"\n",
    "\n",
    "model.save_pretrained(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "\n",
    "print(f\"‚úÖ Model berhasil disimpan di {SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9d346b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teks: Wanginya biasa aja\n",
      "Prediksi Label: Netral\n",
      "Probabilitas: [0.00315966 0.99166673 0.00517357]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    tokens = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors=\"tf\")\n",
    "    logits = model(**tokens).logits\n",
    "    pred = tf.nn.softmax(logits, axis=-1)\n",
    "    label_id = tf.argmax(pred, axis=1).numpy()[0]\n",
    "    return label_id, pred.numpy()[0]\n",
    "\n",
    "sample_text = \"Wanginya biasa aja\"\n",
    "label, prob = predict_sentiment(sample_text)\n",
    "print(\"Teks:\", sample_text)\n",
    "if label == 2: \n",
    "    print(\"Prediksi Label: Positif\")\n",
    "if label == 1: \n",
    "    print(\"Prediksi Label: Netral\")\n",
    "if label == 0: \n",
    "    print(\"Prediksi Label: Negatif\")\n",
    "print(\"Probabilitas:\", prob)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
